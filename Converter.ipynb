{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tool.config import Cfg\n",
    "from tool.translate import build_model, process_input, translate\n",
    "import torch\n",
    "import onnxruntime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = Cfg.load_config_from_file('./weights/custom_config_01102025.yml')\n",
    "config['cnn']['pretrained']=False\n",
    "config['device'] = 'cuda:0'\n",
    "print(config['seq_modeling'])\n",
    "model, vocab = build_model(config)\n",
    "weight_path = './weights/transformerocr.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weight\n",
    "model.load_state_dict(torch.load(weight_path, map_location=torch.device(config['device'])))\n",
    "model = model.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export CNN part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cnn_part(img, save_path, model, max_seq_length=128, sos_token=1, eos_token=2): \n",
    "    with torch.no_grad(): \n",
    "        src = model.cnn(img)\n",
    "        torch.onnx.export(model.cnn, img, save_path, export_params=True, opset_version=12, do_constant_folding=True, verbose=True, input_names=['img'], output_names=['output'], dynamic_axes={'img': {3: 'lenght'}, 'output': {0: 'channel'}})\n",
    "    \n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9995/3405515023.py:4: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(model.cnn, img, save_path, export_params=True, opset_version=12, do_constant_folding=True, verbose=True, input_names=['img'], output_names=['output'], dynamic_axes={'img': {3: 'lenght'}, 'output': {0: 'channel'}})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%img : Float(1, 3, 32, *, strides=[45600, 15200, 475, 1], requires_grad=0, device=cuda:0),\n",
      "      %model.last_conv_1x1.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %model.last_conv_1x1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %onnx::Conv_180 : Float(64, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_181 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_183 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_184 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_186 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_187 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_189 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_190 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_192 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_193 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_195 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_196 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_198 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_199 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_201 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_202 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_204 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_205 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_207 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_208 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_210 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_211 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_213 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_214 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_216 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_217 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_219 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_220 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_222 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_223 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_225 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %onnx::Conv_226 : Float(512, strides=[1], requires_grad=0, device=cuda:0)):\n",
      "  %/model/features/features.0/Conv_output_0 : Float(1, 64, 32, *, strides=[972800, 15200, 475, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.0/Conv\"](%img, %onnx::Conv_180, %onnx::Conv_181), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.0 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.2/Relu_output_0 : Float(1, 64, 32, *, strides=[972800, 15200, 475, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.2/Relu\"](%/model/features/features.0/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.2 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.3/Conv_output_0 : Float(1, 64, 32, *, strides=[972800, 15200, 475, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.3/Conv\"](%/model/features/features.2/Relu_output_0, %onnx::Conv_183, %onnx::Conv_184), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.3 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.5/Relu_output_0 : Float(1, 64, 32, *, strides=[972800, 15200, 475, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.5/Relu\"](%/model/features/features.3/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.5 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.6/AveragePool_output_0 : Float(1, 64, 16, *, strides=[242688, 3792, 237, 1], requires_grad=0, device=cuda:0) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/model/features/features.6/AveragePool\"](%/model/features/features.5/Relu_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.AvgPool2d::features.6 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/pooling.py:773:0\n",
      "  %/model/features/features.7/Conv_output_0 : Float(1, 128, 16, *, strides=[485376, 3792, 237, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.7/Conv\"](%/model/features/features.6/AveragePool_output_0, %onnx::Conv_186, %onnx::Conv_187), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.7 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.9/Relu_output_0 : Float(1, 128, 16, *, strides=[485376, 3792, 237, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.9/Relu\"](%/model/features/features.7/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.9 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.10/Conv_output_0 : Float(1, 128, 16, *, strides=[485376, 3792, 237, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.10/Conv\"](%/model/features/features.9/Relu_output_0, %onnx::Conv_189, %onnx::Conv_190), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.10 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.12/Relu_output_0 : Float(1, 128, 16, *, strides=[485376, 3792, 237, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.12/Relu\"](%/model/features/features.10/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.12 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.13/AveragePool_output_0 : Float(1, 128, 8, *, strides=[120832, 944, 118, 1], requires_grad=0, device=cuda:0) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/model/features/features.13/AveragePool\"](%/model/features/features.12/Relu_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.AvgPool2d::features.13 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/pooling.py:773:0\n",
      "  %/model/features/features.14/Conv_output_0 : Float(1, 256, 8, *, strides=[241664, 944, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.14/Conv\"](%/model/features/features.13/AveragePool_output_0, %onnx::Conv_192, %onnx::Conv_193), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.14 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.16/Relu_output_0 : Float(1, 256, 8, *, strides=[241664, 944, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.16/Relu\"](%/model/features/features.14/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.16 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.17/Conv_output_0 : Float(1, 256, 8, *, strides=[241664, 944, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.17/Conv\"](%/model/features/features.16/Relu_output_0, %onnx::Conv_195, %onnx::Conv_196), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.17 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.19/Relu_output_0 : Float(1, 256, 8, *, strides=[241664, 944, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.19/Relu\"](%/model/features/features.17/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.19 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.20/Conv_output_0 : Float(1, 256, 8, *, strides=[241664, 944, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.20/Conv\"](%/model/features/features.19/Relu_output_0, %onnx::Conv_198, %onnx::Conv_199), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.20 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.22/Relu_output_0 : Float(1, 256, 8, *, strides=[241664, 944, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.22/Relu\"](%/model/features/features.20/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.22 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.23/Conv_output_0 : Float(1, 256, 8, *, strides=[241664, 944, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.23/Conv\"](%/model/features/features.22/Relu_output_0, %onnx::Conv_201, %onnx::Conv_202), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.23 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.25/Relu_output_0 : Float(1, 256, 8, *, strides=[241664, 944, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.25/Relu\"](%/model/features/features.23/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.25 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.26/AveragePool_output_0 : Float(1, 256, 4, *, strides=[120832, 472, 118, 1], requires_grad=0, device=cuda:0) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[2, 1], pads=[0, 0, 0, 0], strides=[2, 1], onnx_name=\"/model/features/features.26/AveragePool\"](%/model/features/features.25/Relu_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.AvgPool2d::features.26 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/pooling.py:773:0\n",
      "  %/model/features/features.27/Conv_output_0 : Float(1, 512, 4, *, strides=[241664, 472, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.27/Conv\"](%/model/features/features.26/AveragePool_output_0, %onnx::Conv_204, %onnx::Conv_205), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.27 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.29/Relu_output_0 : Float(1, 512, 4, *, strides=[241664, 472, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.29/Relu\"](%/model/features/features.27/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.29 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.30/Conv_output_0 : Float(1, 512, 4, *, strides=[241664, 472, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.30/Conv\"](%/model/features/features.29/Relu_output_0, %onnx::Conv_207, %onnx::Conv_208), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.30 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.32/Relu_output_0 : Float(1, 512, 4, *, strides=[241664, 472, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.32/Relu\"](%/model/features/features.30/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.32 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.33/Conv_output_0 : Float(1, 512, 4, *, strides=[241664, 472, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.33/Conv\"](%/model/features/features.32/Relu_output_0, %onnx::Conv_210, %onnx::Conv_211), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.33 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.35/Relu_output_0 : Float(1, 512, 4, *, strides=[241664, 472, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.35/Relu\"](%/model/features/features.33/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.35 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.36/Conv_output_0 : Float(1, 512, 4, *, strides=[241664, 472, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.36/Conv\"](%/model/features/features.35/Relu_output_0, %onnx::Conv_213, %onnx::Conv_214), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.36 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.38/Relu_output_0 : Float(1, 512, 4, *, strides=[241664, 472, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.38/Relu\"](%/model/features/features.36/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.38 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.39/AveragePool_output_0 : Float(1, 512, 2, *, strides=[120832, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[2, 1], pads=[0, 0, 0, 0], strides=[2, 1], onnx_name=\"/model/features/features.39/AveragePool\"](%/model/features/features.38/Relu_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.AvgPool2d::features.39 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/pooling.py:773:0\n",
      "  %/model/features/features.40/Conv_output_0 : Float(1, 512, 2, *, strides=[120832, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.40/Conv\"](%/model/features/features.39/AveragePool_output_0, %onnx::Conv_216, %onnx::Conv_217), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.40 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.42/Relu_output_0 : Float(1, 512, 2, *, strides=[120832, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.42/Relu\"](%/model/features/features.40/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.42 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.43/Conv_output_0 : Float(1, 512, 2, *, strides=[120832, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.43/Conv\"](%/model/features/features.42/Relu_output_0, %onnx::Conv_219, %onnx::Conv_220), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.43 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.45/Relu_output_0 : Float(1, 512, 2, *, strides=[120832, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.45/Relu\"](%/model/features/features.43/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.45 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.46/Conv_output_0 : Float(1, 512, 2, *, strides=[120832, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.46/Conv\"](%/model/features/features.45/Relu_output_0, %onnx::Conv_222, %onnx::Conv_223), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.46 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.48/Relu_output_0 : Float(1, 512, 2, *, strides=[120832, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.48/Relu\"](%/model/features/features.46/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.48 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.49/Conv_output_0 : Float(1, 512, 2, *, strides=[120832, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.49/Conv\"](%/model/features/features.48/Relu_output_0, %onnx::Conv_225, %onnx::Conv_226), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.49 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/features/features.51/Relu_output_0 : Float(1, 512, 2, *, strides=[120832, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/model/features/features.51/Relu\"](%/model/features/features.49/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.51 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/functional.py:1699:0\n",
      "  %/model/features/features.52/AveragePool_output_0 : Float(1, 512, 2, *, strides=[120832, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/model/features/features.52/AveragePool\"](%/model/features/features.51/Relu_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.AvgPool2d::features.52 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/pooling.py:773:0\n",
      "  %/model/last_conv_1x1/Conv_output_0 : Float(1, 256, 2, *, strides=[60416, 236, 118, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/model/last_conv_1x1/Conv\"](%/model/features/features.52/AveragePool_output_0, %model.last_conv_1x1.weight, %model.last_conv_1x1.bias), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model/torch.nn.modules.conv.Conv2d::last_conv_1x1 # /home/hungtrieu07/miniconda3/envs/vietocr_onnx/lib/python3.12/site-packages/torch/nn/modules/conv.py:543:0\n",
      "  %/model/Transpose_output_0 : Float(1, 256, *, 2, strides=[60416, 236, 1, 118], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/model/Transpose\"](%/model/last_conv_1x1/Conv_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model # /home/hungtrieu07/ConvertVietOcr2Onnx/model/backbone/vgg.py:40:0\n",
      "  %/model/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/model/Shape\"](%/model/Transpose_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model # /home/hungtrieu07/ConvertVietOcr2Onnx/model/backbone/vgg.py:41:0\n",
      "  %/model/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/model/Constant\"](), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model # /home/hungtrieu07/ConvertVietOcr2Onnx/model/backbone/vgg.py:41:0\n",
      "  %/model/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/model/Constant_1\"](), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model # /home/hungtrieu07/ConvertVietOcr2Onnx/model/backbone/vgg.py:41:0\n",
      "  %/model/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/model/Constant_2\"](), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model # /home/hungtrieu07/ConvertVietOcr2Onnx/model/backbone/vgg.py:41:0\n",
      "  %/model/Slice_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/model/Slice\"](%/model/Shape_output_0, %/model/Constant_1_output_0, %/model/Constant_2_output_0, %/model/Constant_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model # /home/hungtrieu07/ConvertVietOcr2Onnx/model/backbone/vgg.py:41:0\n",
      "  %/model/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/model/Constant_3\"](), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model # /home/hungtrieu07/ConvertVietOcr2Onnx/model/backbone/vgg.py:41:0\n",
      "  %/model/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/model/Concat\"](%/model/Slice_output_0, %/model/Constant_3_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model # /home/hungtrieu07/ConvertVietOcr2Onnx/model/backbone/vgg.py:41:0\n",
      "  %/model/Reshape_output_0 : Float(*, *, *, strides=[60416, 236, 1], requires_grad=0, device=cuda:0) = onnx::Reshape[onnx_name=\"/model/Reshape\"](%/model/Transpose_output_0, %/model/Concat_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model # /home/hungtrieu07/ConvertVietOcr2Onnx/model/backbone/vgg.py:41:0\n",
      "  %output : Float(*, *, *, strides=[1, 60416, 236], requires_grad=0, device=cuda:0) = onnx::Transpose[perm=[2, 0, 1], onnx_name=\"/model/Transpose_1\"](%/model/Reshape_output_0), scope: model.backbone.cnn.CNN::/model.backbone.vgg.Vgg::model # /home/hungtrieu07/ConvertVietOcr2Onnx/model/backbone/vgg.py:42:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img = torch.rand(1, 3, 32, 475, device=torch.device(config['device']))\n",
    "src = convert_cnn_part(img, './weight_onnx/cnn.onnx', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderWrapper(torch.nn.Module):\n",
    "    def __init__(self, transformer):\n",
    "        super().__init__()\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def forward(self, src):\n",
    "        return self.transformer.forward_encoder(src)\n",
    "\n",
    "\n",
    "class DecoderWrapper(torch.nn.Module):\n",
    "    def __init__(self, transformer):\n",
    "        super().__init__()\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def forward(self, tgt, memory):\n",
    "        return self.transformer.forward_decoder(tgt, memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_encoder_part(model, src, save_path):\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    encoder_module = EncoderWrapper(model.transformer)\n",
    "    encoder_module.eval()\n",
    "    encoder_module.to(src.device)\n",
    "    with torch.no_grad():\n",
    "        memory = encoder_module(src)\n",
    "        torch.onnx.export(\n",
    "            encoder_module,\n",
    "            src,\n",
    "            save_path,\n",
    "            export_params=True,\n",
    "            opset_version=11,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['src'],\n",
    "            output_names=['memory'],\n",
    "            dynamic_axes={\n",
    "                'src': {0: 'seq_len', 1: 'batch'},\n",
    "                'memory': {0: 'seq_len', 1: 'batch'},\n",
    "            },\n",
    "        )\n",
    "    return memory.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = convert_encoder_part(model, src, './weight_onnx/encoder.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_decoder_part(model, tgt, memory, save_path):\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    decoder_module = DecoderWrapper(model.transformer)\n",
    "    decoder_module.eval()\n",
    "    decoder_module.to(tgt.device)\n",
    "    memory = memory.to(tgt.device)\n",
    "    with torch.no_grad():\n",
    "        torch.onnx.export(\n",
    "            decoder_module,\n",
    "            (tgt, memory),\n",
    "            save_path,\n",
    "            export_params=True,\n",
    "            opset_version=11,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['tgt', 'memory'],\n",
    "            output_names=['logits', 'memory_out'],\n",
    "            dynamic_axes={\n",
    "                'tgt': {0: 'tgt_seq', 1: 'batch'},\n",
    "                'memory': {0: 'src_seq', 1: 'batch'},\n",
    "                'logits': {0: 'batch', 1: 'tgt_seq'},\n",
    "                'memory_out': {0: 'src_seq', 1: 'batch'},\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = img.device\n",
    "tgt = torch.full((1, img.shape[0]), 1, dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manhbui/manhbq_workspace/ConvertVietOcr2Onnx/model/seqmodel/seq2seq.py:93: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert (output == hidden).all()\n"
     ]
    }
   ],
   "source": [
    "convert_decoder_part(model, tgt, memory, './weight_onnx/decoder.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = onnx.load('./weight/cnn.onnx')\n",
    "decoder = onnx.load('./weight/encoder.onnx')\n",
    "encoder = onnx.load('./weight/decoder.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm model has valid schema\n",
    "onnx.checker.check_model(cnn)\n",
    "onnx.checker.check_model(decoder)\n",
    "onnx.checker.check_model(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph torch-jit-export (\\n  %tgt[INT64, 1]\\n  %hidden[FLOAT, 1x256]\\n  %encoder_outputs[FLOAT, channel_inputx1x512]\\n) initializers (\\n  %attention.attn.bias[FLOAT, 256]\\n  %embedding.weight[FLOAT, 233x256]\\n  %fc_out.weight[FLOAT, 233x1024]\\n  %fc_out.bias[FLOAT, 233]\\n  %116[INT64, 1]\\n  %117[INT64, 1]\\n  %118[INT64, 1]\\n  %119[INT64, 1]\\n  %120[FLOAT, 768x256]\\n  %121[FLOAT, 256x1]\\n  %139[FLOAT, 1x768x768]\\n  %140[FLOAT, 1x768x256]\\n  %141[FLOAT, 1x1536]\\n) {\\n  %13 = Unsqueeze[axes = [0]](%tgt)\\n  %14 = Gather(%embedding.weight, %13)\\n  %15 = Shape(%encoder_outputs)\\n  %16 = Constant[value = <Scalar Tensor []>]()\\n  %17 = Gather[axis = 0](%15, %16)\\n  %18 = Unsqueeze[axes = [1]](%hidden)\\n  %22 = Unsqueeze[axes = [0]](%17)\\n  %24 = Concat[axis = 0](%116, %22, %117)\\n  %26 = Unsqueeze[axes = [0]](%17)\\n  %28 = Concat[axis = 0](%118, %26, %119)\\n  %29 = Shape(%24)\\n  %30 = ConstantOfShape[value = <Tensor>](%29)\\n  %31 = Expand(%18, %30)\\n  %32 = Tile(%31, %28)\\n  %33 = Transpose[perm = [1, 0, 2]](%encoder_outputs)\\n  %34 = Concat[axis = 2](%32, %33)\\n  %36 = MatMul(%34, %120)\\n  %37 = Add(%36, %attention.attn.bias)\\n  %38 = Tanh(%37)\\n  %40 = MatMul(%38, %121)\\n  %41 = Squeeze[axes = [2]](%40)\\n  %42 = Softmax[axis = 1](%41)\\n  %43 = Unsqueeze[axes = [1]](%42)\\n  %44 = Transpose[perm = [1, 0, 2]](%encoder_outputs)\\n  %45 = MatMul(%43, %44)\\n  %46 = Transpose[perm = [1, 0, 2]](%45)\\n  %47 = Concat[axis = 2](%14, %46)\\n  %48 = Unsqueeze[axes = [0]](%hidden)\\n  %106, %107 = GRU[hidden_size = 256, linear_before_reset = 1](%47, %139, %140, %141, %, %48)\\n  %108 = Squeeze[axes = [1]](%106)\\n  %109 = Squeeze[axes = [0]](%14)\\n  %110 = Squeeze[axes = [0]](%108)\\n  %111 = Squeeze[axes = [0]](%46)\\n  %112 = Concat[axis = 1](%110, %111, %109)\\n  %output = Gemm[alpha = 1, beta = 1, transB = 1](%112, %fc_out.weight, %fc_out.bias)\\n  %hidden_out = Squeeze[axes = [0]](%107)\\n  %last = Squeeze[axes = [1]](%43)\\n  return %output, %hidden_out, %last\\n}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Print a human readable representation of the graph\n",
    "onnx.helper.printable_graph(encoder.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('./sample/35944.png')\n",
    "img = process_input(img, config['dataset']['image_height'], \n",
    "                config['dataset']['image_min_width'], config['dataset']['image_max_width'])  \n",
    "img = img.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mâm non: 141 thí sinh'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = translate(img, model)[0].tolist()\n",
    "s = vocab.decode(s)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with ONNX Runtime's Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inference session\n",
    "cnn_session = onnxruntime.InferenceSession(\"./weight_onnx/cnn.onnx\")\n",
    "encoder_session = onnxruntime.InferenceSession(\"./weight_onnx/encoder.onnx\")\n",
    "decoder_session = onnxruntime.InferenceSession(\"./weight_onnx/decoder.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_onnx(img, session, max_seq_length=128, sos_token=1, eos_token=2):\n",
    "    \"\"\"data: BxCxHxW\"\"\"\n",
    "    cnn_session, encoder_session, decoder_session = session\n",
    "\n",
    "    cnn_input = {cnn_session.get_inputs()[0].name: img}\n",
    "    src = cnn_session.run(None, cnn_input)[0]\n",
    "\n",
    "    encoder_input = {encoder_session.get_inputs()[0].name: src}\n",
    "    memory = encoder_session.run(None, encoder_input)[0]\n",
    "\n",
    "    translated_sentence = [[sos_token] * img.shape[0]]\n",
    "    max_length = 0\n",
    "\n",
    "    while max_length <= max_seq_length and not all(\n",
    "        np.any(np.asarray(translated_sentence).T == eos_token, axis=1)\n",
    "    ):\n",
    "        tgt_inp = np.asarray(translated_sentence, dtype=np.int64)\n",
    "        decoder_input = {\n",
    "            decoder_session.get_inputs()[0].name: tgt_inp,\n",
    "            decoder_session.get_inputs()[1].name: memory,\n",
    "        }\n",
    "\n",
    "        logits, memory = decoder_session.run(None, decoder_input)\n",
    "        output = torch.from_numpy(logits)\n",
    "\n",
    "        values, indices = torch.topk(output, 1)\n",
    "        indices = indices[:, -1, 0]\n",
    "        indices = indices.tolist()\n",
    "\n",
    "        translated_sentence.append(indices)\n",
    "        max_length += 1\n",
    "\n",
    "    translated_sentence = np.asarray(translated_sentence).T\n",
    "\n",
    "    return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mâm non: 141 thí sinh'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = (cnn_session, encoder_session, decoder_session)\n",
    "img_np = img.detach().cpu().numpy()\n",
    "s = translate_onnx(img_np, session)[0].tolist()\n",
    "s = vocab.decode(s)\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vietocr_onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
